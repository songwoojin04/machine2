{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-TOSlZyWV_9y6m2IcIve33K3jiIsfJqc",
      "authorship_tag": "ABX9TyMNUphehBBWCDL0vtCMG4oY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songwoojin04/machine2/blob/main/10week/1D_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D8dLXWIjxAc6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(filepath):\n",
        "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "    return dataframe.values\n",
        "\n",
        "def load_group(filenames, prefix=''):\n",
        "    loaded = list()\n",
        "    for name in filenames:\n",
        "        data = load_file(prefix + name)\n",
        "        loaded.append(data)\n",
        "    loaded = np.dstack(loaded)\n",
        "    return loaded\n",
        "\n",
        "def load_dataset_group(group, prefix=''):\n",
        "    filepath = prefix + group + '/Inertial Signals/'\n",
        "    filenames = list()\n",
        "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "    X = load_group(filenames, filepath)\n",
        "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "khnMO7_oxGSE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(prefix=''):\n",
        "    trainX, trainy = load_dataset_group('train', prefix + '/content/drive/MyDrive/Colab Notebooks/10주차/data/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/')\n",
        "    testX, testy = load_dataset_group('test', prefix + '/content/drive/MyDrive/Colab Notebooks/10주차/data/human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/')\n",
        "\n",
        "    trainy = trainy - 1\n",
        "    testy = testy - 1\n",
        "    trainy_one_hot = to_categorical(trainy)\n",
        "    testy_one_hot = to_categorical(testy)\n",
        "    print(trainX.shape, trainy.shape, trainy_one_hot.shape, testX.shape, testy.shape, testy_one_hot.shape)\n",
        "    return trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot"
      ],
      "metadata": {
        "id": "xnLcCU1rxHce"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot = load_dataset()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_val,y_train_one_hot,y_val_one_hot,y_train,y_val=train_test_split(trainX, trainy_one_hot, trainy,test_size=0.2,random_state=100)\n",
        "\n",
        "X_train.shape,X_val.shape,y_train_one_hot.shape,y_val_one_hot.shape,y_train.shape,y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88qOno1DxIge",
        "outputId": "778ed99e-ff81-48da-95c2-ba0720be07d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
            "/tmp/ipython-input-3497204177.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7352, 128, 9) (7352, 1) (7352, 6) (2947, 128, 9) (2947, 1) (2947, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5881, 128, 9), (1471, 128, 9), (5881, 6), (1471, 6), (5881, 1), (1471, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train_one_hot.shape[1]"
      ],
      "metadata": {
        "id": "iTT24nfRxJlL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "mu = X_train.mean(axis=(0,1), keepdims=True)\n",
        "std = X_train.std(axis=(0,1), keepdims=True) + 1e-6\n",
        "X_train_s = (X_train - mu) / std\n",
        "X_val_s = (X_val - mu) / std\n",
        "testX_s = (testX - mu) / std\n",
        "\n",
        "n_timesteps, n_features, n_outputs = X_train_s.shape[1], X_train_s.shape[2], y_train_one_hot.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.3), input_shape=(n_timesteps, n_features)))\n",
        "model.add(Bidirectional(LSTM(64, dropout=0.3)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "cb = [\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-5, verbose=1),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "hist = model.fit(\n",
        "    X_train_s, y_train_one_hot,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_s, y_val_one_hot),\n",
        "    callbacks=cb,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(testX_s, testy_one_hot, verbose=0)\n",
        "print('TEST ACC:', round(test_acc, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48zW0RouxK6P",
        "outputId": "870df960-7caa-45d3-bcbd-062389d8b320"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.5452 - loss: 1.1161 - val_accuracy: 0.9041 - val_loss: 0.2455 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8568 - loss: 0.3573 - val_accuracy: 0.9225 - val_loss: 0.1899 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8850 - loss: 0.2951 - val_accuracy: 0.9368 - val_loss: 0.1373 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.2140 - val_accuracy: 0.9429 - val_loss: 0.1416 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9060 - loss: 0.2190 - val_accuracy: 0.9109 - val_loss: 0.1903 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9165 - loss: 0.1948 - val_accuracy: 0.9307 - val_loss: 0.1571 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9177 - loss: 0.1818 - val_accuracy: 0.8851 - val_loss: 0.2038 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9204 - loss: 0.1934 - val_accuracy: 0.9409 - val_loss: 0.1609 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9020 - loss: 0.2215\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9019 - loss: 0.2220 - val_accuracy: 0.9028 - val_loss: 0.1943 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9201 - loss: 0.1831 - val_accuracy: 0.8892 - val_loss: 0.2542 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9290 - loss: 0.1525 - val_accuracy: 0.8511 - val_loss: 0.4315 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9255 - loss: 0.1756 - val_accuracy: 0.9001 - val_loss: 0.2427 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9267 - loss: 0.1472 - val_accuracy: 0.8749 - val_loss: 0.2554 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9384 - loss: 0.1436\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9383 - loss: 0.1437 - val_accuracy: 0.8892 - val_loss: 0.2967 - learning_rate: 5.0000e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "TEST ACC: 0.9026\n"
          ]
        }
      ]
    }
  ]
}